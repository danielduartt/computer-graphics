{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTB0R7Go1FpV"
      },
      "source": [
        "#PointNet Classification\n",
        "\n",
        "\n",
        "## **Pointnet é uma rede neural profunda que consome diretamente a nuvem de pontos 3D e fornece uma abordagem unificada para tarefas como classificação e segmentação.**\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://stanford.edu/~rqi/pointnet/images/teaser.jpg\" alt=\"centered image\" />\n",
        "</center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oyBCqGo1FpV"
      },
      "source": [
        "# **1. Install dependency**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvtCvB4T1FpW"
      },
      "source": [
        "# **2. Import necessary library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-10-20T10:31:53.202007Z",
          "iopub.status.busy": "2023-10-20T10:31:53.201677Z",
          "iopub.status.idle": "2023-10-20T10:32:02.243018Z",
          "shell.execute_reply": "2023-10-20T10:32:02.242332Z",
          "shell.execute_reply.started": "2023-10-20T10:31:53.201972Z"
        },
        "id": "iNBaBHlv1FpW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import trimesh\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Configuração de semente para reprodutibilidade\n",
        "tf.random.set_seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDMNVeoA1FpW"
      },
      "source": [
        "# **3. Download the pointcloud data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from download_modelnet import download\n",
        "\n",
        "# Baixar e extrair o dataset\n",
        "DATA_DIR = download()\n",
        "print(f\"Dataset disponível em: {DATA_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIqbpK5N1FpX"
      },
      "source": [
        "# **4. Visualize the pointcloud data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-20T10:32:18.234034Z",
          "iopub.status.busy": "2023-10-20T10:32:18.233735Z",
          "iopub.status.idle": "2023-10-20T10:32:18.290117Z",
          "shell.execute_reply": "2023-10-20T10:32:18.289201Z",
          "shell.execute_reply.started": "2023-10-20T10:32:18.234009Z"
        },
        "id": "5F3IR8lU1FpX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "mesh = trimesh.load(os.path.join(DATA_DIR, \"chair/train/chair_0002.off\"))\n",
        "mesh.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-20T10:32:18.291628Z",
          "iopub.status.busy": "2023-10-20T10:32:18.291319Z",
          "iopub.status.idle": "2023-10-20T10:32:19.293754Z",
          "shell.execute_reply": "2023-10-20T10:32:19.292721Z",
          "shell.execute_reply.started": "2023-10-20T10:32:18.291605Z"
        },
        "id": "yxo1XtUN1FpX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "points = mesh.sample(2048)\n",
        "\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "ax = fig.add_subplot(111, projection=\"3d\")\n",
        "ax.scatter(points[:, 0], points[:, 1], points[:, 2])\n",
        "ax.set_axis_off()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeTllkbv1FpX"
      },
      "source": [
        "# **5. Data preprocessing and augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-20T10:37:23.651292Z",
          "iopub.status.busy": "2023-10-20T10:37:23.650606Z",
          "iopub.status.idle": "2023-10-20T10:37:23.658089Z",
          "shell.execute_reply": "2023-10-20T10:37:23.65708Z",
          "shell.execute_reply.started": "2023-10-20T10:37:23.651256Z"
        },
        "id": "Vg4Qw1sf1FpX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def parse_dataset(num_points=2048):\n",
        "\n",
        "    train_points = []\n",
        "    train_labels = []\n",
        "    test_points = []\n",
        "    test_labels = []\n",
        "    class_map = {}\n",
        "    folders = glob.glob(os.path.join(DATA_DIR, \"[!README]*\"))\n",
        "\n",
        "    for i, folder in enumerate(folders):\n",
        "        print(\"processing class: {}\".format(os.path.basename(folder)))\n",
        "        # store folder name with ID so we can retrieve later\n",
        "        class_map[i] = folder.split(\"/\")[-1]\n",
        "        # gather all files\n",
        "        train_files = glob.glob(os.path.join(folder, \"train/*\"))\n",
        "        test_files = glob.glob(os.path.join(folder, \"test/*\"))\n",
        "\n",
        "        for f in train_files:\n",
        "            train_points.append(trimesh.load(f).sample(num_points))\n",
        "            train_labels.append(i)\n",
        "\n",
        "        for f in test_files:\n",
        "            test_points.append(trimesh.load(f).sample(num_points))\n",
        "            test_labels.append(i)\n",
        "\n",
        "    return (\n",
        "        np.array(train_points),\n",
        "        np.array(test_points),\n",
        "        np.array(train_labels),\n",
        "        np.array(test_labels),\n",
        "        class_map,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-20T10:37:33.788251Z",
          "iopub.status.busy": "2023-10-20T10:37:33.787559Z",
          "iopub.status.idle": "2023-10-20T10:43:07.265661Z",
          "shell.execute_reply": "2023-10-20T10:43:07.26458Z",
          "shell.execute_reply.started": "2023-10-20T10:37:33.78822Z"
        },
        "id": "H7DSSt2y1FpX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "NUM_POINTS = 2048\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_points, test_points, train_labels, test_labels, CLASS_MAP = parse_dataset(\n",
        "    NUM_POINTS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-20T10:43:07.267958Z",
          "iopub.status.busy": "2023-10-20T10:43:07.267676Z",
          "iopub.status.idle": "2023-10-20T10:43:11.147509Z",
          "shell.execute_reply": "2023-10-20T10:43:11.146801Z",
          "shell.execute_reply.started": "2023-10-20T10:43:07.267933Z"
        },
        "id": "EOwrfYhV1FpX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def augment(points, label):\n",
        "    # jitter points\n",
        "    points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float64)\n",
        "    # shuffle points\n",
        "    points = tf.random.shuffle(points)\n",
        "    return points, label\n",
        "\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_points, train_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_points, test_labels))\n",
        "\n",
        "train_dataset = train_dataset.shuffle(len(train_points)).map(augment).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.shuffle(len(test_points)).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-20T10:43:11.148739Z",
          "iopub.status.busy": "2023-10-20T10:43:11.148476Z",
          "iopub.status.idle": "2023-10-20T10:43:11.153704Z",
          "shell.execute_reply": "2023-10-20T10:43:11.152988Z",
          "shell.execute_reply.started": "2023-10-20T10:43:11.148717Z"
        },
        "id": "TrkGHfzv1FpX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def conv_bn(x, filters):\n",
        "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
        "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
        "    return layers.Activation(\"relu\")(x)\n",
        "\n",
        "\n",
        "def dense_bn(x, filters):\n",
        "    x = layers.Dense(filters)(x)\n",
        "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
        "    return layers.Activation(\"relu\")(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-20T10:43:11.156919Z",
          "iopub.status.busy": "2023-10-20T10:43:11.156157Z",
          "iopub.status.idle": "2023-10-20T10:43:11.168864Z",
          "shell.execute_reply": "2023-10-20T10:43:11.168Z",
          "shell.execute_reply.started": "2023-10-20T10:43:11.156895Z"
        },
        "id": "SX-Fef9l1FpX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
        "    def __init__(self, num_features, l2reg=0.001):\n",
        "        self.num_features = num_features\n",
        "        self.l2reg = l2reg\n",
        "        self.eye = tf.eye(num_features)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
        "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
        "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
        "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5SniV-T1FpY"
      },
      "source": [
        "# **6. Building the model**\n",
        "\n",
        "<img src=\"https://www.researchgate.net/publication/343806184/figure/fig2/AS:930138283835393@1598773656168/PointNet-10-and-PointNet-12-architectures.jpg\" alt=\"centered image\" />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-20T10:43:11.170127Z",
          "iopub.status.busy": "2023-10-20T10:43:11.169839Z",
          "iopub.status.idle": "2023-10-20T10:43:11.181754Z",
          "shell.execute_reply": "2023-10-20T10:43:11.181175Z",
          "shell.execute_reply.started": "2023-10-20T10:43:11.170104Z"
        },
        "id": "pH8bqjNE1FpY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def tnet(inputs, num_features):\n",
        "\n",
        "    # Initalise bias as the indentity matrix\n",
        "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
        "    reg = OrthogonalRegularizer(num_features)\n",
        "\n",
        "    x = conv_bn(inputs, 32)\n",
        "    x = conv_bn(x, 64)\n",
        "    x = conv_bn(x, 512)\n",
        "    x = layers.GlobalMaxPooling1D()(x)\n",
        "    x = dense_bn(x, 256)\n",
        "    x = dense_bn(x, 128)\n",
        "    x = layers.Dense(\n",
        "        num_features * num_features,\n",
        "        kernel_initializer=\"zeros\",\n",
        "        bias_initializer=bias,\n",
        "        activity_regularizer=reg,\n",
        "    )(x)\n",
        "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
        "    # Apply affine transformation to input features\n",
        "    return layers.Dot(axes=(2, 1))([inputs, feat_T])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-20T10:43:11.183136Z",
          "iopub.status.busy": "2023-10-20T10:43:11.182901Z",
          "iopub.status.idle": "2023-10-20T10:43:11.92782Z",
          "shell.execute_reply": "2023-10-20T10:43:11.926982Z",
          "shell.execute_reply.started": "2023-10-20T10:43:11.183115Z"
        },
        "id": "OZoIUjzM1FpY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(NUM_POINTS, 3))\n",
        "\n",
        "x = tnet(inputs, 3)\n",
        "x = conv_bn(x, 32)\n",
        "x = conv_bn(x, 32)\n",
        "x = tnet(x, 32)\n",
        "x = conv_bn(x, 32)\n",
        "x = conv_bn(x, 64)\n",
        "x = conv_bn(x, 512)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = dense_bn(x, 256)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = dense_bn(x, 128)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-20T10:43:11.929189Z",
          "iopub.status.busy": "2023-10-20T10:43:11.928912Z",
          "iopub.status.idle": "2023-10-20T10:47:24.440203Z",
          "shell.execute_reply": "2023-10-20T10:47:24.439359Z",
          "shell.execute_reply.started": "2023-10-20T10:43:11.929167Z"
        },
        "id": "zBQhthQH1FpY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(train_dataset, epochs=20, validation_data=test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76OBnuxU1FpY"
      },
      "source": [
        "# **7. Test data and Visualize**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-20T10:49:04.381315Z",
          "iopub.status.busy": "2023-10-20T10:49:04.380935Z",
          "iopub.status.idle": "2023-10-20T10:49:05.818824Z",
          "shell.execute_reply": "2023-10-20T10:49:05.817937Z",
          "shell.execute_reply.started": "2023-10-20T10:49:04.381288Z"
        },
        "id": "1pmhHmto1FpY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data = test_dataset.take(1)\n",
        "\n",
        "points, labels = list(data)[0]\n",
        "points = points[:8, ...]\n",
        "labels = labels[:8, ...]\n",
        "\n",
        "# run test data through model\n",
        "preds = model.predict(points)\n",
        "preds = tf.math.argmax(preds, -1)\n",
        "\n",
        "points = points.numpy()\n",
        "\n",
        "# plot points with predicted class and label\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "for i in range(8):\n",
        "    ax = fig.add_subplot(2, 4, i + 1, projection=\"3d\")\n",
        "    ax.scatter(points[i, :, 0], points[i, :, 1], points[i, :, 2])\n",
        "    ax.set_title(\n",
        "        \"pred: {:}, label: {:}\".format(\n",
        "            CLASS_MAP[preds[i].numpy()], CLASS_MAP[labels.numpy()[i]]\n",
        "        )\n",
        "    )\n",
        "    ax.set_axis_off()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R6n5S3n1FpY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcJqmOGG1FpY"
      },
      "source": [
        "## **Credit:https://keras.io/examples/vision/pointnet**\n",
        "\n",
        "⭐️⭐️Thanks for visiting guys⭐️⭐️"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "⭐️⭐️3D-PointCloudClassification⭐️⭐️",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
